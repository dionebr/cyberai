from fastapi import FastAPI, HTTPException, APIRouter
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
from typing import Dict
from src.api.core.llama_client import LlamaClient

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="CyberAI Offensive API", version="1.0")
api_router = APIRouter(prefix="/api")

app.add_middleware(
	CORSMiddleware,
	allow_origins=["*"],
	allow_methods=["*"],
	allow_headers=["*"],
)

class PromptRequest(BaseModel):
	prompt: str
	context: str = ""
	technique: str = ""
	target: str = ""
	options: Dict = {}
	max_tokens: int = 768  # Aumentado para respostas mais completas
	temperature: float = 0.7
	top_p: float = 0.9
	preferred_model: str = "auto"  # "auto", "tinyllama", "mistral"

class ExploitRequest(BaseModel):
	cve: str = ""
	vulnerability_type: str = ""
	target_os: str = ""
	target_app: str = ""
	constraints: Dict = {}

llama_client = None  # Ser√° criado dinamicamente por t√©cnica

TECHNIQUE_PROMPTS = {
	"sql_injection": "Forne√ßa payloads SQL Injection avan√ßados incluindo: time-based, boolean-based, UNION-based, e out-of-band. Inclua t√©cnicas de bypass de WAF.",
	"xss": "Gere payloads XSS completos incluindo: reflected, stored, DOM-based. Inclua evas√µes e polyglots.",
	"rce": "T√©cnicas de Remote Code Execution com exemplos de exploit e bypass de restri√ß√µes.",
	"lfi_rfi": "Payloads para Local File Inclusion e Remote File Inclusion com wrappers PHP e t√©cnicas de filtro bypass.",
	"deserialization": "Exploits para vulnerabilidades de desserializa√ß√£o em diferentes linguagens.",
	"buffer_overflow": "T√©cnicas de buffer overflow com exemplos de exploit development e shellcode crafting.",
	"privesc": "T√©cnicas de privilege escalation para Linux e Windows incluindo kernel exploits, misconfigurations e abuso de servi√ßos.",
	"pivoting": "T√©cnicas de pivoting e movimento lateral em redes.",
	"antivirus_evasion": "T√©cnicas de evas√£o de antiv√≠rus e EDR solutions.",
	"memory_analysis": "T√©cnicas de an√°lise de mem√≥ria e dumping de credenciais.",
	# Telas/m√≥dulos (aliases em pt-br)
	"recon": "Enumera√ß√£o e reconhecimento: nmap agressivo, detec√ß√£o de servi√ßos/ports, subdom√≠nios (amass/subfinder), tecnologias (fingerprinting) e descoberta de diret√≥rios (gobuster/feroxbuster). Entregue comandos pr√°ticos e anota√ß√µes.",
	"payloads": "Gera√ß√£o de payloads ofensivos completos e funcionais: reverse shells multi-plataforma (Bash, Python, PowerShell, Node, PHP, C#, Java), bind shells, meterpreter payloads, web shells, varia√ß√µes com ofusca√ß√£o, encoding, bypass de firewall e evas√£o de antiv√≠rus. Forne√ßa c√≥digo funcional, instru√ß√µes de uso e varia√ß√µes para diferentes cen√°rios.",
	"binary_analysis": "An√°lise de bin√°rios e malware: uso de radare2/Ghidra, strings, syscalls, IoCs, criptografia e padr√µes suspeitos. Forne√ßa passos reproduz√≠veis.",
	"binarios": "An√°lise de bin√°rios e malware: uso de radare2/Ghidra, strings, syscalls, IoCs, criptografia e padr√µes suspeitos. Forne√ßa passos reproduz√≠veis.",
	"post_exploitation": "P√≥s-explora√ß√£o: persist√™ncia, enumera√ß√£o de credenciais, movimento lateral e coleta de evid√™ncias. Inclua comandos e scripts.",
	"post": "P√≥s-explora√ß√£o: persist√™ncia, enumera√ß√£o de credenciais, movimento lateral e coleta de evid√™ncias. Inclua comandos e scripts.",
	"reporting": "Gera√ß√£o de relat√≥rios t√©cnicos: sum√°rio executivo, metodologia, achados com evid√™ncias, risco, recomenda√ß√£o e pr√≥ximos passos.",
	"relatorios": "Gera√ß√£o de relat√≥rios t√©cnicos: sum√°rio executivo, metodologia, achados com evid√™ncias, risco, recomenda√ß√£o e pr√≥ximos passos.",
	"management": "Gest√£o de engajamento: defini√ß√£o de escopo, alvos, m√©tricas e tarefas; checklists e cronograma de execu√ß√£o.",
	"gestao": "Gest√£o de engajamento: defini√ß√£o de escopo, alvos, m√©tricas e tarefas; checklists e cronograma de execu√ß√£o.",
	"dev_tools": "Assistentes de desenvolvimento: templates de c√≥digo, snippets seguros, boas pr√°ticas e exemplos de integra√ß√£o.",
	"ferramentas": "Assistentes de desenvolvimento: templates de c√≥digo, snippets seguros, boas pr√°ticas e exemplos de integra√ß√£o.",
	"threat_intel": "Threat Intelligence: sumarize CVEs/TTPs relevantes, mapeie em MITRE ATT&CK, indique refer√™ncias e indicadores.",
	"intelligence": "Threat Intelligence: sumarize CVEs/TTPs relevantes, mapeie em MITRE ATT&CK, indique refer√™ncias e indicadores.",
	"lab": "Laborat√≥rio: plano de montagem de ambiente de testes isolado, VMs necess√°rias, redes e datasets de pr√°tica.",
	"community": "Comunidade: plugins, integra√ß√µes e recursos compartilhados. Sugira ideias e exemplos de como estender a plataforma.",
	"exploit": "Explora√ß√£o automatizada: identificar vetores plaus√≠veis e gerar PoCs, com recomenda√ß√µes de ferramentas e passos de valida√ß√£o."
    ,"treinamento": "Trilhas de estudo e pr√°tica: CTFs, labs e materiais progressivos focados no objetivo informado. Estruture por n√≠veis e inclua refer√™ncias."
}

@api_router.post("/generate")
async def generate_response(request: PromptRequest):
	technique_prompt = TECHNIQUE_PROMPTS.get(request.technique, "")
	
	# Sistema de prompts otimizado para contexto limitado
	system_prompt = f"""CyberAI - Especialista em Cybersecurity Ofensiva

FOCO: {technique_prompt if technique_prompt else "Cybersecurity geral"}
CONTEXTO: {request.context if request.context else "N/A"}
ALVO: {request.target if request.target else "Sistemas diversos"}

FORMATO DE RESPOSTA:
üéØ Objetivo e uso pr√°tico
üîß C√≥digo/comandos funcionais comentados  
‚ö° Varia√ß√µes e otimiza√ß√µes
üõ°Ô∏è Evas√£o/bypass quando aplic√°vel
üìö Refer√™ncias t√©cnicas

Regras: Seja t√©cnico, detalhado, funcional. Use markdown para c√≥digo. Evite disclaimers.

PERGUNTA:"""
	
	full_prompt = f"{system_prompt}\n{request.prompt}"
	
	# Determinar modelo baseado no modelo preferido
	model_type = "auto"
	if request.preferred_model == "tinyllama":
		model_type = "tiny"
	elif request.preferred_model == "mistral":
		model_type = "standard"
	
	# Cria cliente espec√≠fico para a t√©cnica/modelo
	client = LlamaClient(technique=request.technique, model_type=model_type)
	
	try:
		response_text = client.generate(
			prompt=full_prompt,
			temperature=request.temperature,
			top_p=request.top_p,
			max_tokens=request.max_tokens
		)
		
		# Info sobre o modelo usado
		model_info = client.model_config["description"]
		
		return JSONResponse(content={
			"response": response_text,
			"technique": request.technique,
			"context": request.context,
			"model_used": model_info
		})
	except RuntimeError as e:
		logger.error(f"Modelo indispon√≠vel: {str(e)}")
		raise HTTPException(status_code=503, detail=str(e))
	except Exception as e:
		logger.error(f"Error generating response: {str(e)}")
		raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/generate_exploit")
async def generate_exploit(request: ExploitRequest):
	exploit_prompt = f"""
	Gere um exploit completo para:
	CVE: {request.cve}
	Tipo de vulnerabilidade: {request.vulnerability_type}
	Sistema Alvo: {request.target_os}
	Aplica√ß√£o: {request.target_app}
	Restri√ß√µes: {request.constraints}
	Inclua:
	1. An√°lise da vulnerabilidade
	2. C√≥digo de explora√ß√£o completo
	3. Instru√ß√µes de compila√ß√£o e execu√ß√£o
	4. T√©cnicas de evas√£o se necess√°rio
	5. Exemplo de uso
	"""
	
	# Usa modelo padr√£o para exploits (mais complexo)
	client = LlamaClient(technique="exploit_complex", model_type="standard")
	
	try:
		response_text = client.generate(
			prompt=exploit_prompt,
			temperature=0.7,
			top_p=0.9,
			max_tokens=512  
		)
		return JSONResponse(content={
			"exploit_code": response_text,
			"metadata": {
				"cve": request.cve,
				"target_os": request.target_os,
				"target_app": request.target_app
			}
		})
	except RuntimeError as e:
		logger.error(f"Modelo indispon√≠vel: {str(e)}")
		raise HTTPException(status_code=503, detail=str(e))
	except Exception as e:
		logger.error(f"Error generating exploit: {str(e)}")
		raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/techniques")
async def get_techniques():
	return {"techniques": list(TECHNIQUE_PROMPTS.keys())}

@api_router.get("/models")
async def get_models():
	from src.api.core.llama_client import MODELS_CONFIG, FAST_TECHNIQUES
	
	return {
		"models": [
			{
				"name": "TinyLlama (R√°pido)",
				"description": MODELS_CONFIG["tiny"]["description"],
				"techniques": list(FAST_TECHNIQUES),
				"max_tokens": MODELS_CONFIG["tiny"]["max_tokens"]
			},
			{
				"name": "Mistral (Completo)", 
				"description": MODELS_CONFIG["standard"]["description"],
				"techniques": "Outras t√©cnicas complexas",
				"max_tokens": MODELS_CONFIG["standard"]["max_tokens"]
			}
		]
	}

@api_router.get("/gpu-status")
async def get_gpu_status():
	"""
	Endpoint para verificar o status atual da GPU
	"""
	try:
		import subprocess
		from src.api.core.llama_client import detect_gpu_support
		
		# Verificar se NVIDIA est√° dispon√≠vel no sistema
		try:
			result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
			nvidia_available = result.returncode == 0
			if nvidia_available:
				# Extrair info b√°sica da GPU
				lines = result.stdout.split('\n')
				gpu_info = "GPU detectada"
				for line in lines:
					if "GTX" in line or "RTX" in line or "GeForce" in line:
						gpu_info = line.split()[2:5]  # Nome da GPU
						gpu_info = " ".join(gpu_info)
						break
			else:
				gpu_info = None
		except:
			nvidia_available = False
			gpu_info = None
		
		# Verificar se llama-cpp-python tem suporte CUDA
		cuda_support = detect_gpu_support()
		
		# Determinar status
		if nvidia_available and cuda_support:
			status = "GPU Dispon√≠vel e Ativada"
			gpu_enabled = True
		elif nvidia_available and not cuda_support:
			status = "GPU Detectada (CUDA n√£o compilado)"
			gpu_enabled = False
		else:
			status = "CPU Only"
			gpu_enabled = False
		
		return JSONResponse(content={
			"gpu_enabled": gpu_enabled,
			"nvidia_available": nvidia_available,
			"cuda_support": cuda_support,
			"status": status,
			"gpu_info": gpu_info or "Nenhuma GPU detectada"
		})
		
	except Exception as e:
		logger.error(f"Erro ao verificar status GPU: {str(e)}")
		return JSONResponse(content={
			"gpu_enabled": False,
			"nvidia_available": False,
			"cuda_support": False,
			"status": "Erro ao verificar GPU",
			"gpu_info": str(e)
		})

class GPUToggleRequest(BaseModel):
	enable_gpu: bool

@api_router.post("/toggle-gpu")
async def toggle_gpu_mode(request: GPUToggleRequest):
	"""
	Endpoint para alternar entre modo CPU e GPU
	Usa o gpu_manager.py para fazer a troca real dos containers
	"""
	try:
		import subprocess
		import os
		import asyncio
		
		# Caminho do projeto
		project_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
		gpu_manager_path = os.path.join(project_path, "gpu_manager.py")
		
		target_mode = "gpu" if request.enable_gpu else "cpu"
		
		logger.info(f"üîÑ Tentando alternar para modo {target_mode.upper()}...")
		
		try:
			# Executar gpu_manager em background
			process = subprocess.Popen(
				["python", gpu_manager_path, target_mode],
				cwd=project_path,
				stdout=subprocess.PIPE,
				stderr=subprocess.PIPE,
				text=True
			)
			
			# Aguardar conclus√£o (m√°ximo 30 segundos)
			stdout, stderr = process.communicate(timeout=30)
			
			if process.returncode == 0:
				logger.info(f"‚úÖ Modo {target_mode.upper()} ativado com sucesso")
				
				# Aguardar containers estarem prontos
				await asyncio.sleep(3)
				
				return JSONResponse(content={
					"success": True,
					"gpu_enabled": request.enable_gpu,
					"status": f"{target_mode.upper()} Ativado",
					"message": f"Sistema alterado para modo {target_mode.upper()} com sucesso!",
					"details": stdout.strip() if stdout else ""
				})
			else:
				error_msg = stderr.strip() if stderr else "Erro desconhecido"
				logger.error(f"‚ùå Erro ao alternar para {target_mode}: {error_msg}")
				
				return JSONResponse(content={
					"success": False,
					"gpu_enabled": not request.enable_gpu,  # Manter estado anterior
					"status": "Erro na Alterna√ß√£o",
					"message": f"Erro ao alternar para {target_mode}: {error_msg}"
				}, status_code=400)
				
		except subprocess.TimeoutExpired:
			process.kill()
			logger.error("‚è∞ Timeout ao alternar modo GPU/CPU")
			return JSONResponse(content={
				"success": False,
				"gpu_enabled": not request.enable_gpu,
				"status": "Timeout",
				"message": "Timeout ao alternar modo. Tente novamente."
			}, status_code=408)
			
	except Exception as e:
		logger.error(f"Erro cr√≠tico ao alternar GPU: {str(e)}")
		return JSONResponse(content={
			"success": False,
			"gpu_enabled": False,
			"status": "Erro Cr√≠tico",
			"message": f"Erro interno: {str(e)}"
		}, status_code=500)

app.include_router(api_router)

if __name__ == "__main__":
	import uvicorn
	uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
